{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN4JGDfxy3Mpj7+yGZcQjRo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NluXn9wEq79T","executionInfo":{"status":"ok","timestamp":1730195559329,"user_tz":-120,"elapsed":406,"user":{"displayName":"Maksym Shkarupylo","userId":"07461948744333407479"}},"outputId":"6c5472ff-f939-48e6-b6db-1bac28c3c344"},"outputs":[{"output_type":"stream","name":"stdout","text":["Пункт 1: Класичний нейрон\n","Вхід: 0.0, Вихід: 0.09665598365289567\n","Вхід: 0.1, Вихід: 0.10079679317337406\n","\n","Пункт 2: Елементарний двошаровий персептрон\n","Вхід: 0.0, Вихід: 0.10039114630197979\n","Вхід: 0.1, Вихід: 0.10011309213589634\n","\n","Пункт 3: Двошаровий персептрон (2-3-1)\n","Вхід: [0. 0.], Вихід: 0.17646590879110607\n","Вхід: [0.  0.1], Вихід: 0.17706798669346935\n","Вхід: [0.1 0. ], Вихід: 0.17889546089243516\n","Вхід: [0.2 0.3], Вихід: 0.18323159924259028\n"]}],"source":["import numpy as np\n","\n","# Сигмоїдна функція активації та її похідна\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","    return x * (1 - x)\n","\n","# Клас для класичного нейрону\n","class Neuron:\n","    def __init__(self):\n","        self.weight = np.random.rand()\n","        self.bias = np.random.rand()\n","\n","    def train(self, x, y, learning_rate=0.5, epochs=1000):\n","        for _ in range(epochs):\n","            pred = self.predict(x)\n","            error = y - pred\n","            self.weight += learning_rate * error * x * sigmoid_derivative(pred)\n","            self.bias += learning_rate * error * sigmoid_derivative(pred)\n","\n","    def predict(self, x):\n","        return sigmoid(x * self.weight + self.bias)\n","\n","# Клас для елементарного двошарового персептрону (1-1-1)\n","class SimplePerceptron:\n","    def __init__(self):\n","        self.hidden_neuron = Neuron()\n","        self.output_neuron = Neuron()\n","\n","    def train(self, x, y, learning_rate=0.5, epochs=1000):\n","        for _ in range(epochs):\n","            hidden_output = self.hidden_neuron.predict(x)\n","            pred = self.output_neuron.predict(hidden_output)\n","            error = y - pred\n","            self.output_neuron.weight += learning_rate * error * hidden_output * sigmoid_derivative(pred)\n","            self.output_neuron.bias += learning_rate * error * sigmoid_derivative(pred)\n","\n","            hidden_error = error * self.output_neuron.weight * sigmoid_derivative(hidden_output)\n","            self.hidden_neuron.weight += learning_rate * hidden_error * x * sigmoid_derivative(hidden_output)\n","            self.hidden_neuron.bias += learning_rate * hidden_error * sigmoid_derivative(hidden_output)\n","\n","    def predict(self, x):\n","        hidden_output = self.hidden_neuron.predict(x)\n","        return self.output_neuron.predict(hidden_output)\n","\n","# Клас для двошарового персептрону із структурою 2-3-1\n","class TwoLayerPerceptron:\n","    def __init__(self):\n","        self.hidden_layer = [Neuron() for _ in range(3)]\n","        self.output_neuron = Neuron()\n","\n","    def train(self, x, y, learning_rate=0.3):\n","        for epoch in range(1000):\n","            for i in range(len(x)):\n","                hidden_outputs = np.array([self.hidden_layer[j].predict(x[i][j % len(x[i])]) for j in range(3)])\n","\n","                pred = self.output_neuron.predict(np.sum(hidden_outputs))\n","                error = y[i] - pred\n","\n","                self.output_neuron.weight += learning_rate * error * np.sum(hidden_outputs) * sigmoid_derivative(pred)\n","                self.output_neuron.bias += learning_rate * error * sigmoid_derivative(pred)\n","\n","                for j, neuron in enumerate(self.hidden_layer):\n","                    hidden_error = error * self.output_neuron.weight * sigmoid_derivative(hidden_outputs[j])\n","                    neuron.weight += learning_rate * hidden_error * x[i][j % len(x[i])] * sigmoid_derivative(hidden_outputs[j])\n","                    neuron.bias += learning_rate * hidden_error * sigmoid_derivative(hidden_outputs[j])\n","\n","    def predict(self, x):\n","        hidden_outputs = np.array([self.hidden_layer[j].predict(x[j % len(x)]) for j in range(3)])\n","        return self.output_neuron.predict(np.sum(hidden_outputs))\n","\n","# Приклади роботи для пунктів 1 та 2\n","\n","# Пункт 1: Тестування класичного нейрону\n","print(\"Пункт 1: Класичний нейрон\")\n","neuron = Neuron()\n","x_train = np.array([0, 0.1])  # Вхідні значення\n","y_train = np.array([0, 0.1])  # Очікуваний результат (наприклад, реалізація AND)\n","\n","# Навчання нейрону\n","neuron.train(x_train[1], y_train[1])\n","for x in x_train:\n","    print(f\"Вхід: {x}, Вихід: {neuron.predict(x)}\")\n","\n","# Пункт 2: Тестування елементарного двошарового персептрону (1-1-1)\n","print(\"\\nПункт 2: Елементарний двошаровий персептрон\")\n","simple_perceptron = SimplePerceptron()\n","simple_perceptron.train(x_train[1], y_train[1])\n","for x in x_train:\n","    print(f\"Вхід: {x}, Вихід: {simple_perceptron.predict(x)}\")\n","\n","# Пункт 3: Тестування двошарового персептрону (2-3-1)\n","print(\"\\nПункт 3: Двошаровий персептрон (2-3-1)\")\n","perceptron = TwoLayerPerceptron()\n","x_train = np.array([[0, 0], [0, 0.1], [0.1, 0], [0.2, 0.3]])  # Вхідні значення для двох змінних\n","y_train = np.array([0, 0.1, 0.1, 0.5])  # Очікуваний результат (наприклад, XOR)\n","perceptron.train(x_train, y_train)\n","\n","# Перевірка результатів для двошарового персептрону\n","for x in x_train:\n","    print(f\"Вхід: {x}, Вихід: {perceptron.predict(x)}\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"8WEosX3vq-Ld"},"execution_count":null,"outputs":[]}]}